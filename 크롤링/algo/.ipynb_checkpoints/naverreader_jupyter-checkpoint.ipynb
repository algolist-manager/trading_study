{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      full_code short_code codeName marketName\n",
      "0  KR7079940003    A079940      가비아     KOSDAQ\n",
      "1  KR7078890001    A078890    가온미디어     KOSDAQ\n",
      "2  KR7000500009    A000500     가온전선      KOSPI\n",
      "3  KR7192410009    A192410      감마누     KOSDAQ\n",
      "4  KR7000860007    A000860   강남제비스코      KOSPI\n",
      "   codeName short_code\n",
      "0      삼성전자    A005930\n",
      "1    SK하이닉스    A000660\n",
      "2     삼성전자우    A005935\n",
      "3  삼성바이오로직스    A207940\n",
      "4     NAVER    A035420\n",
      "[['20190212', '44650', '46250', '44650', '46050', '13184367', 'A005930'], ['20190213', '46400', '46700', '46000', '46200', '11299738', 'A005930'], ['20190214', '46600', '47500', '46150', '47500', '17259341', 'A005930'], ['20190215', '46750', '46850', '45650', '46050', '10554643', 'A005930']]\n",
      "[Errno 2] No such file or directory: './10year.pickle'\n",
      "A005930\n",
      "A000660\n",
      "A005935\n",
      "A207940\n",
      "A035420\n",
      "A051910\n",
      "A005380\n",
      "A006400\n",
      "A068270\n",
      "A012330\n",
      "크롤링 하는데 소요된 시간 : 4.7초\n",
      "              open    high     low   close  volume short_code\n",
      "date                                                         \n",
      "2009-12-24   15700   15880   15640   15800  407107    A005930\n",
      "2009-12-28   15800   15860   15580   15740  235595    A005930\n",
      "2009-12-29   15720   15740   15600   15720  136900    A005930\n",
      "2009-12-30   15760   15980   15740   15980  295625    A005930\n",
      "2010-01-04   16060   16180   16000   16180  239271    A005930\n",
      "...            ...     ...     ...     ...     ...        ...\n",
      "2020-02-10  227500  230000  225000  228500  183144    A012330\n",
      "2020-02-11  229000  240500  228500  237500  302565    A012330\n",
      "2020-02-12  238000  243500  237500  242500  268281    A012330\n",
      "2020-02-13  241000  242500  237500  239000  252113    A012330\n",
      "2020-02-14  234500  240500  234000  239000  132532    A012330\n",
      "\n",
      "[23299 rows x 6 columns]\n",
      "Wall time : 0.08030193249384562분\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "개발 환경 : windows 10 / Anaconda3 python=3.6 64BIT\n",
    "\"\"\"\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from finance_util import link_list\n",
    "## 제가 올린 파일들 중 finance_util은 크롤링하면서 필요하다 싶은 함수를 혼자서 만드는데, 그것들을 모두 모아 놓은 파일입니다.\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "class naverreader:\n",
    "    \"\"\"\n",
    "    Naver 주식에서 종목을 가져오는 클래스입니다. 저는 크롤링 대상 웹사이트별로 클래스의 구조를 가능하면 비슷하게 두려고 합니다.\n",
    "    1. 개별 주식 데이터 가져오는 메서드\n",
    "    3. 해당 사이트에 있는 전 종목을 가져오는 메서드 : 1.개별 주식 데이터 가져오는 메서드를 전 종목에 걸쳐 돌려주는 메서드입니다.\n",
    "    4. 업데이트 할 수 있는 메서드 : 3번을 통해 자신의 컴퓨터에 데이터를 보관하고 있다면, 매일 새로운 데이터를 추가해주는 메서드입니다.\n",
    "    5. 현재 데이터 베이스를 조회하는 메서드 : 지금까지 모아둔 데이터 베이스를 조회합니다. 업데이트가 되어 있다면 바로 파일을 주고, 업데이트가\n",
    "    되어 있지 않으면 4.의 업데이트를 거친 후 데이터를 보여줍니다.\n",
    "    6. 기타 : 필요한 다른 데이터들(full_code.pickle : 종목명과 종목코드를 담고 있는 DataFrame. Naver_companies : 네이버에 있는 모든\n",
    "    회사 종목명과 코드를 담고 있는 DataFrame.)\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.full_code = pd.read_pickle('./full_code.pickle')\n",
    "        self.companies = pd.read_pickle('./naver_companies.pickle')\n",
    "\n",
    "    def get_stock_price(self, num_code, days):\n",
    "        \"\"\"\n",
    "        - 종목코드와 오늘로부터의 일자를 입력하면 한 종목의 과거 데이터를 가져올 수 있습니다.\n",
    "        * 이 주가 데이터는 액면분할까지는 조정해주지만 배당이나 무상증자를 조정하지는 않는 것 같습니다.\n",
    "        ** 거래 정지 종목인 경우에는 주가가 0으로 뜬다는 문제가 있기 때문에 데이터 전처리가 중요합니다.\n",
    "        :param num_code: (str) '005930' 형식의 기업 코드입니다.\n",
    "        :param days: (int) 이 함수를 실행하는 날짜부터 며칠 전까지의 데이터를 가져올 것인지 결정합니다. 365를 입력해도 1년이\n",
    "        되지는 않습니다. 거래일 기준이기 떄문에 1년 보다 더 많은 데이터가 들어옵니다. 만약 1년치가 필요하다면 252가 적당할 듯 싶습니다.\n",
    "        :return: (list) 데이터 프레임 형식이 아니라 리스트로 반환합니다. 전 종목 데이터를 가져올 때 종목마다 데이터프레임으로 바꾸면\n",
    "        속도가 매우 느려지기 때문에 리스트로 반환합니다.\n",
    "        \"\"\"\n",
    "        url = 'https://fchart.stock.naver.com/sise.nhn' # 네이버 금융의 차트가 있는 화면입니다.\n",
    "        payload = {\n",
    "            'symbol': num_code,\n",
    "            'timeframe': 'day',\n",
    "            'count': days,\n",
    "            'requestType': 0\n",
    "        }\n",
    "        req = requests.get(url, params=payload).text\n",
    "        soup = bs(req, 'lxml')\n",
    "        row_list = []\n",
    "        for item in soup.findAll('item'):\n",
    "            row = item['data'].split('|')\n",
    "            row.append('A' + num_code)\n",
    "            row_list.append(row)\n",
    "\n",
    "        return row_list\n",
    "\n",
    "\n",
    "    def get_naver_total(self, days): # 여기서 얻은 데이터는 관리 종목인 경우 값이 0이다.\n",
    "        \"\"\"\n",
    "        위에서의 get_stock_price 메서드를 모든 종목의 주식에 대해 적용합니다. 이 방법을 한 번 돌릴 때마다 시간이 굉장히 오래 걸리기\n",
    "        때문에 처음 데이터 베이스를 구축할 때 한번 돌리고, 추후에는 업데이트를 통해 데이터를 모은다는 개념으로 접근하였습니다.\n",
    "        :param days: (int) get_stock_price의 인수 days와 같은 개념입니다.\n",
    "        :return: (pandas.DataFrame) 전 종목의 과거 days의 모든 값을 줍니다.\n",
    "        \"\"\"\n",
    "        super_list = []\n",
    "        for i, code in enumerate(self.companies['short_code']):\n",
    "            try:\n",
    "                short_code = code\n",
    "                print(code) # 시간이 오래 걸리므로 현재 어디까지 진행되었는지 보기 위해 넣었습니다.\n",
    "                num_code = short_code[1:]\n",
    "                super_list.append(self.get_stock_price(num_code, days=days))\n",
    "                if i==9: break # -> 전 종목을 다 돌리려면 시간이 오래 걸리므로, 테스트용으로 일단 10종목만 가져와볼 때 쓰시면 됩니다.\n",
    "            except KeyError:\n",
    "                pass\n",
    "\n",
    "        linked = pd.DataFrame(link_list(super_list))\n",
    "        linked.columns = ['date', 'open', 'high', 'low', 'close', 'volume', 'short_code']\n",
    "        linked['date'] = linked['date'].apply(lambda x: pd.to_datetime(x))\n",
    "        linked[['open', 'high', 'low', 'close', 'volume']] = linked[\n",
    "            ['open', 'high', 'low', 'close', 'volume']].applymap(lambda x: int(x))\n",
    "        linked.set_index('date', inplace=True)\n",
    "\n",
    "        return linked\n",
    "\n",
    "    def get_current_price(self):\n",
    "        \"\"\"\n",
    "         매일 자신이 가지고 있는 데이터 베이스를 업데이트 하기 위해서 전 종목의 현재가를 보여줍니다. 이 가격은 장이 종료된 후에는\n",
    "         종가가 됩니다. 그래서 장 종료 이후 그 날 하루의 종가를 모으고, 기존의 데이터와 붙이면, 업데이트가 됩니다.\n",
    "        :return: (pandas.DataFrame) 전 종목의 현재가.\n",
    "        \"\"\"\n",
    "\n",
    "        url = 'https://finance.naver.com/sise/field_submit.nhn?menu=market_sum&returnUrl=http%3A%2F%2Ffinance.naver' \\\n",
    "              '.com%2Fsise%2Fsise_market_sum.nhn%3F%26page%3D1&fieldIds=quant&fieldIds=open_val&fieldIds=high_val' \\\n",
    "              '&fieldIds=low_val '\n",
    "        payload = dict()\n",
    "        company_pages = []\n",
    "        for sosok in [0, 1]:  # 0은 코스피, 1은 코스닥\n",
    "            payload['sosok'] = sosok\n",
    "            for page_num in range(1, 33):  # 마지막 페이지는 거의 33\n",
    "                print('페이지 수 : {}'.format(page_num))\n",
    "                payload['page'] = page_num\n",
    "                req = requests.get(url, params=payload).text\n",
    "                company_pages.append(pd.read_html(req)[1][['시가', '고가', '저가', '현재가', '거래량', '종목명']])\n",
    "                if page_num == 1: break\n",
    "            if sosok == 0: break\n",
    "\n",
    "        df = pd.concat(company_pages)\n",
    "        current_prices = df\n",
    "        current_prices.dropna(inplace=True)\n",
    "        current_prices.reset_index(drop=True, inplace=True)\n",
    "        current_prices.index = [datetime.today()] * len(current_prices)\n",
    "        current_prices.columns = ['open', 'high', 'low', 'close', 'volume', 'codeName']\n",
    "        return current_prices\n",
    "\n",
    "    def load_data(self): ## 현재가만 구할 수 있으며 종가를 완벽하게 저장하기 위해서는 6시가 넘어야 한다.\n",
    "        self.saved = pd.read_pickle('./10year.pickle')\n",
    "        result = self.saved\n",
    "        if self.saved.index.unique().sort_values()[-1] < pd.to_datetime(datetime.today().strftime('%Y%m%d')):## 조건문을 안 넣으면 중첩된 날짜가 생길 우려\n",
    "            print('업데이트 필요')\n",
    "            current_prices = self.get_current_price()\n",
    "            full_code = self.full_code\n",
    "            merged = current_prices.merge(full_code, on=['codeName'])\n",
    "            adjust = merged[['open', 'high', 'low', 'close', 'volume', 'short_code']].copy()\n",
    "            adjust.index = [pd.to_datetime(datetime.today().strftime('%Y%m%d'))] * len(adjust)\n",
    "            result = pd.concat([self.saved, adjust])\n",
    "            result.to_pickle('./10year.pickle')\n",
    "\n",
    "        else:\n",
    "            print('업데이트 사항 없음')\n",
    "        return result\n",
    "\n",
    "\n",
    "    def get_naver_companies(self):\n",
    "        \"\"\"\n",
    "        네이버의 시가 총액을 볼 수 있는 화면에서 네이버 금융에서 다루고 있는 전 종목을 가져오려고 합니다. 네이버 금융에서는 코스피,\n",
    "        코스닥은 다루고 있지만 코넥스, K-OTC 등의 종목들은 다루고 있지 않습니다.\n",
    "        \"\"\"\n",
    "        url = 'https://finance.naver.com/sise/sise_market_sum.nhn'\n",
    "        payload = dict()\n",
    "        company_pages = []\n",
    "        for j in [0, 1]:  # 0은 코스피, 1은 코스닥\n",
    "            for i in range(1, 33):\n",
    "                payload['sosok'] = j\n",
    "                payload['page'] = i\n",
    "                req = requests.get(url, params=payload).text\n",
    "                company_pages.append(pd.read_html(req)[1])\n",
    "\n",
    "        df = pd.concat(company_pages)\n",
    "        codenames = df['종목명']\n",
    "        codenames.columns = ['codeName']\n",
    "        codenames.dropna(inplace=True)\n",
    "        codenames.reset_index(drop=True, inplace=True)\n",
    "\n",
    "        codenames_df = pd.DataFrame(codenames)\n",
    "        companies = codenames_df.merge(self.full_code, on=['codeName'])\n",
    "        return companies\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    st = time.time() # 실행시간 체크를 위해 시간을 찍습니다.\n",
    "\n",
    "    naver = naverreader()\n",
    "    print(naver.full_code.head()) ## 코드와 종목명을 담고 있는 데이터 프레임입니다.\n",
    "    print(naver.companies.head()) ## 네이버에 등록된 회사들입니다.\n",
    "\n",
    "    samsung = naver.get_stock_price(num_code='005930', days=250) # 오늘로부터 1년치 삼성전자 데이터\n",
    "    print(samsung[:4])\n",
    "\n",
    "    try:\n",
    "        full_data = naver.load_data()\n",
    "        print(full_data)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    # 내 컴퓨터에 보관된 데이터를 가져오는 메서드입니다. 하지만 전 종목 데이터를 아직 수집하지 않은 경우 파일불러오기를 할 때 오류가 납니다.\n",
    "    # [Errno 2] No such file or directory: './10year.pickle'\n",
    "    # 따라서 아래의 get_naver_total 함수를 이용해 result를 얻고\n",
    "    # result.to_pickle('./10year.pickle')\n",
    "    # 을 이용하여 저장을 해두시면 load_data()가 가능합니다.\n",
    "\n",
    "\n",
    "    try:\n",
    "        crawling_start = time.time()\n",
    "        result = naver.get_naver_total(2500) ## 대략 10년치를 가져오는 메서드입니다. 일단 테스트용으로 10개만 돌려봅니다.\n",
    "        crawling_end = time.time()\n",
    "        processing_time = round(crawling_end-crawling_start, 2)\n",
    "        print(\"크롤링 하는데 소요된 시간 : {}초\".format(processing_time))\n",
    "        # 제 컴퓨터는 10종목을 뽑는데 4.91초가 나오네요.\n",
    "        # 총 2500 종목의 10년치 데이터를 다 가져온다고 생각했을 때 5.46초를 250회 시행하므로 250*4.91/60=20.45분이 소요되겠군요.\n",
    "        # Pycharm에서 실행했을 떄는 18분 정도가 소요되었습니다.\n",
    "        # 위의 수치는 CPU로만 돌린 것입니다. \n",
    "        # GPU를 쓸 수 있다면 성능은 훨씬 향상됩니다. google colab에서 제공하는 GPU를 사용하니 실행시간이 1/3 정도 줄어들었습니다.\n",
    "        print(result)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "    print('Wall time : {}분'.format((time.time()-st)/60))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# main의 실행내역을 한 줄씩 나눠서 실행한 결과입니다. 좀 더 보기 좋아보이네요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "naver = naverreader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>full_code</th>\n",
       "      <th>short_code</th>\n",
       "      <th>codeName</th>\n",
       "      <th>marketName</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KR7079940003</td>\n",
       "      <td>A079940</td>\n",
       "      <td>가비아</td>\n",
       "      <td>KOSDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>KR7078890001</td>\n",
       "      <td>A078890</td>\n",
       "      <td>가온미디어</td>\n",
       "      <td>KOSDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KR7000500009</td>\n",
       "      <td>A000500</td>\n",
       "      <td>가온전선</td>\n",
       "      <td>KOSPI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KR7192410009</td>\n",
       "      <td>A192410</td>\n",
       "      <td>감마누</td>\n",
       "      <td>KOSDAQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>KR7000860007</td>\n",
       "      <td>A000860</td>\n",
       "      <td>강남제비스코</td>\n",
       "      <td>KOSPI</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      full_code short_code codeName marketName\n",
       "0  KR7079940003    A079940      가비아     KOSDAQ\n",
       "1  KR7078890001    A078890    가온미디어     KOSDAQ\n",
       "2  KR7000500009    A000500     가온전선      KOSPI\n",
       "3  KR7192410009    A192410      감마누     KOSDAQ\n",
       "4  KR7000860007    A000860   강남제비스코      KOSPI"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver.full_code.head() ## 코드와 종목명을 담고 있는 데이터 프레임입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>codeName</th>\n",
       "      <th>short_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>삼성전자</td>\n",
       "      <td>A005930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SK하이닉스</td>\n",
       "      <td>A000660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>삼성전자우</td>\n",
       "      <td>A005935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>삼성바이오로직스</td>\n",
       "      <td>A207940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NAVER</td>\n",
       "      <td>A035420</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   codeName short_code\n",
       "0      삼성전자    A005930\n",
       "1    SK하이닉스    A000660\n",
       "2     삼성전자우    A005935\n",
       "3  삼성바이오로직스    A207940\n",
       "4     NAVER    A035420"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver.companies.head() ## 네이버에 등록된 회사들입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['20190212', '44650', '46250', '44650', '46050', '13184367', 'A005930'],\n",
       " ['20190213', '46400', '46700', '46000', '46200', '11299738', 'A005930'],\n",
       " ['20190214', '46600', '47500', '46150', '47500', '17259341', 'A005930'],\n",
       " ['20190215', '46750', '46850', '45650', '46050', '10554643', 'A005930']]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samsung = naver.get_stock_price(num_code='005930', days=250) # 오늘로부터 1년치 삼성전자 데이터\n",
    "samsung[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: './10year.pickle'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    full_data = naver.load_data()\n",
    "    print(full_data)\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "# 내 컴퓨터에 보관된 데이터를 가져오는 메서드입니다. 하지만 전 종목 데이터를 아직 수집하지 않은 경우 파일불러오기를 할 때 오류가 납니다.\n",
    "# [Errno 2] No such file or directory: './10year.pickle'\n",
    "# 따라서 아래의 get_naver_total 함수를 이용해 result를 얻고\n",
    "# result.to_pickle('./10year.pickle')\n",
    "# 을 이용하여 저장을 해두시면 load_data()가 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A005930\n",
      "A000660\n",
      "A005935\n",
      "A207940\n",
      "A035420\n",
      "A051910\n",
      "A005380\n",
      "A006400\n",
      "A068270\n",
      "A012330\n",
      "크롤링 하는데 소요된 시간 : 4.92초\n",
      "              open    high     low   close  volume short_code\n",
      "date                                                         \n",
      "2009-12-24   15700   15880   15640   15800  407107    A005930\n",
      "2009-12-28   15800   15860   15580   15740  235595    A005930\n",
      "2009-12-29   15720   15740   15600   15720  136900    A005930\n",
      "2009-12-30   15760   15980   15740   15980  295625    A005930\n",
      "2010-01-04   16060   16180   16000   16180  239271    A005930\n",
      "...            ...     ...     ...     ...     ...        ...\n",
      "2020-02-10  227500  230000  225000  228500  183144    A012330\n",
      "2020-02-11  229000  240500  228500  237500  302565    A012330\n",
      "2020-02-12  238000  243500  237500  242500  268281    A012330\n",
      "2020-02-13  241000  242500  237500  239000  252113    A012330\n",
      "2020-02-14  234500  240500  234000  239000  132532    A012330\n",
      "\n",
      "[23299 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    crawling_start = time.time()\n",
    "    result = naver.get_naver_total(2500) ## 대략 10년치를 가져오는 메서드입니다. 일단 테스트용으로 10개만 돌려봅니다.\n",
    "    crawling_end = time.time()\n",
    "    processing_time = round(crawling_end-crawling_start, 2)\n",
    "    print(\"크롤링 하는데 소요된 시간 : {}초\".format(processing_time))\n",
    "    # 제 컴퓨터는 10종목을 뽑는데 4.38초가 나오네요.\n",
    "    # 총 2500 종목의 10년치 데이터를 다 가져온다고 생각했을 때 4.38초를 250회 시행하므로 250*4.38/60=18.25분이 소요되겠군요.\n",
    "    # GPU를 쓸 수 있다면 성능은 훨씬 향상됩니다. google colab에서 제공하는 GPU를 사용하니 실행시간이 1/3로 줄어들었습니다.\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
